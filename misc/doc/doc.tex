
\documentclass[a4paper,oneside,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} 
\usepackage{hyperref}
\usepackage{amsmath,amssymb}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{url}
\usepackage{xspace}
\usepackage[french]{babel}
\usepackage{multicol}
\usepackage{geometry}

\geometry{hmargin=2cm,vmargin=1.5cm}

\title{Système distribué pour le traitement de données\\
Documentation
}

\author{Jordan DE GEA - Guillaume THIOLLIERE - Vincent TAVERNIER - Pierre HEINISCH\\
William DUCLOT - Mathieu STOFFEL - Joseph PEREZ - Imane Rachdi - Salim ABOUBACAR}

\begin{document}

\maketitle

Nous avons choisi de travailler sur le sujet IDA. Il s'agit de traiter des données sous forme de flux. \\

\section{Thème} 

Notre thème est intitulé "Twitter et Meteo". Notre objectif est de récupérer le contentement des utilisateurs de Twitter sur des régions données par rapport à la météo. 

\section{Le Projet}

\subsection{Composants}
% expliquer ce que permet le composant, comment il s'utilise, les hypothèses qu'il fait, les garanties qu'il offre, etc. 

\subsubsection{Kafka}
%Expliquer Kafka
%%% Par ailleurs, cette partie est indépendante de votre application. A titre d'exemple, Kafka n'est pas un composant qui "a pour objectif de récupérer des flux Twitter". Kafka est un composant généraliste qui joue un role de "message broker" et que vous utilisez dans votre application pour récupérer des flux Twitter.

Kafka est un système de messagerie distribué. Il joue le r\^ole de \textit{broker} pour des flux de données : des \textbf{producteurs} envoient des flux de données à Kafka, qui va les stocker et permettre à des \textbf{consommateurs} de traiter ces flux.

Chaque flux peut \^etre partitionné, permettant à plusieurs consommateurs de travailler sur le m\^eme flux en parallèle. Une partition est une suite de messages ordonnée et immutable, chaque message ayant un identifiant qui lui est affecté.

Kafka fonctionne en cluster, permettant de répliquer les partitions pour être tolérant aux fautes, d'automatiquement balancer les consommateurs en cas de faute et d'être très facilement horizontalement scalable.

Dans notre cas, Kafka sera utilisé pour s'abonner aux flux Twitter et météo, et partitionner ces flux par région.

\textbf{Utilisé par :} Netflix, PayPal, Uber...

\subsubsection{Flink}
% Expliquer Flink
Apache Flink est un framework de traitement temps-réel. Il permet donc de traiter des données arrivant en temps-réel, plutôt que par \textit{batch}, et donc d'avoir un temps de latence extr\^emement court.

En utilisant Flink pour traiter les flux fournis par Kafka, nous conservons l'aspect temps-réel qui fait la particularité de Twitter.

\textbf{Utilisé par :} Bouygues Telecom, Alibaba, Amadeus, ATOS...

\subsubsection{HBase}
HBase est une base de données distribuée non-relationnelle. Cette technologie permet de stocker de larges quantités de données, et est très efficace pour les applications ayant un haut débit de données.

Hbase gère la réplication au sein du cluster, le sharding et le balancement de la charge. Le requêtage est extrêmement rapide et des des filtres peuvent être appliqués.

\textbf{Utilisé par :} Adobe, Airbnb, Facebook Messenger, Netflix...

\subsubsection{Zeppelin}
%Expliquer Zeppelin
Zeppelin fournis une interface web de visualisation de données. Son principal intérêt est d'être capable d'analyser et mettre en forme de grandes quantités de données, et de s'intégrer très bien aux autres technologies (faisant partie de l'écosystème Apache).

Cet outil fournis de nombreuses graphes pour la visualisation de données, permettant de rapidement et facilement travailler sur de gros volumes.

\subsection{Architecture des composants}
% Le titre de la section 2.2 est mal choisi. Par ailleurs, cette section mélange actuellement plusieurs éléments : 
% - l'architecture générale du système : combien de machines pour chaque composant, les liens entre ces composants (i.e. quel composant communique avec quel composant).
% - les garanties fournies par le système
% Par ailleurs, la partie "Hypothèses" n'a pas sa place ici ; elle a sa place dans la description de chaque composant (pour expliquer les hypothèses que fait le composant et ce qu'il garantit en termes de tolérance aux fautes).


Hypothèses : 
\begin{itemize}
	\item Pannes franches
	\item Canaux de communications fiables
	\item Détecteur de fautes parfait
\end{itemize}

Configuration : 
\begin{itemize}
	\item Kafka sera installé sur 3 machines si 3 machines ou plus sont en vie. Et sur toutes les machines si moins de 3 machines sont en vie. Un détecteur de faute se chargera de garantir la propriété "3 machines en vie".
	\item Flink sera installé sur autant de machines que nous avons. Dans le cas où nous avons plus de 10 machines, Flink sera installé sur des machines où Kafka n'est pas installé. Un détecteur de faute se chargera de garantir les règles que nous appliquerons sur les configuration de Kafka. 
	\item HBase sera installé sur 3 machines si 3 machines ou plus sont en vie. Et sur toutes les machines si moins de 3 machines sont en vie. L'algorithme Rowkey sera utilisé pour garantir les propriétés ACID.
	\item Zeppelin sera installé sur 3 machines. Zeppelin sera répliqué. Un détecteur de faute se chargera de garantir la propriété "3 machines en vie".
\end{itemize}

Comportement : 
\begin{itemize}
	\item Lorsque que 3 ou plus machines sont en vie, alors le service fonctionne correctement.
	\item Lorsque que 2 machines sont en vie, alors le service fonctionne correctement et cherche à utiliser une nouvelle machine.
	\item Lorsque que 1 machine est en vie, alors le service se bloque jusqu'à ce qu'au moins une autre machine soit ajouté au système. 
\end{itemize}


\subsection{Premiers objectifs}
%La section 2.3 devrait être fusionnée avec la partie "architecture générale du système" citée précédemment.


Nous commencerons par nous fixer un faible nombre de régions (Paris et Londres par exemple). Nous appliquerons nos algorithmes sur ces régions. 
Afin de mesurer le contentement des personnes, nous utiliserons des mots clef, hastags et emojis contenu dans les messages twitter. 

Kafka sélectionnera seulement les tweets dans les régions sélectionnées et gardera seulement les données météorologiques sur ces régions. 


\end{document}
