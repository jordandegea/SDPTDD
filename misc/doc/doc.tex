
\documentclass[a4paper,oneside,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} 
\usepackage{hyperref}
\usepackage{amsmath,amssymb}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{url}
\usepackage{xspace}
\usepackage[french]{babel}
\usepackage{multicol}
\usepackage{geometry}

\geometry{hmargin=2cm,vmargin=1.5cm}

\title{Twitter \& Humeur : Documentation\\
\small{Système distribué pour le traitement de données}
}

\author{Jordan DE GEA - Guillaume THIOLLIERE - Vincent TAVERNIER - Pierre HEINISCH\\
William DUCLOT - Mathieu STOFFEL - Joseph PEREZ - Imane Rachdi - Salim ABOUBACAR}

\begin{document}

\maketitle


\section{Sujet - "Twitter \& Humeur"}

L'objectif de ce projet est d'estimer l'\textbf{humeur} des gens dans différentes régions. Nous récupérons des flux twitters sur différentes régions. Sur chaque tweet, nous attribuons une appréciation. Puis nous stockons chaque tweet traité et son appreciation dans la base. 


\section{Composants}

\subsection{Kafka}

\textbf{Kafka} est un système de messagerie distribué. Il joue le rôle de 
{broker} pour des flux de données : des \textbf{producteurs} envoient des flux de données à Kafka, qui va les stocker et permettre à des \textbf{consommateurs} de traiter ces flux.

Chaque flux peut être partitionné, permettant à plusieurs consommateurs de travailler sur le même flux en parallèle. Une partition est une suite de messages ordonnés et immutables, chaque message ayant un identifiant qui lui est affecté.

\textbf{Kafka} fonctionne en cluster, permettant de répliquer les partitions pour être tolérant aux fautes, d'automatiquement redistribuer les consommateurs en cas de faute et d'être très facilement horizontalement scalable.

Dans notre cas, Kafka sera utilisé pour s'abonner aux flux Twitter et météo, et partitionner ces flux par région.

\textbf{Kafka} est tolérant aux pannes franches, du fait de la réplication des partitions sur les différents serveurs (réplication configurable). Cette tolérance est valable si on considère que les communications entre producteur et cluster Kafka sont fiables. En effet la réplication se fait au sein du cluster Kafka, les serveurs de réplication (\textit{followers}) pour une partition donnée copiant la partition depuis le serveur référent (\textit{leader}) pour cette partition. Dés lors si le producteur ne parvient pas à contacter le serveur référent, le message ne sera pas renvoyé et sera perdu. 

\textbf{Utilisé par :} Netflix, PayPal, Uber...


\subsection{Flink}

\textbf{Apache Flink} est un framework de traitement temps-réel. Il permet donc de traiter des données arrivant en temps-réel, plutôt que par \textit{batch}, et donc d'avoir un temps de latence extrêmement court.

En utilisant \textbf{Flink} pour traiter les flux fournis par Kafka, nous conservons l'aspect temps-réel qui fait la particularité de Twitter.

\textbf{Utilisé par :} Bouygues Telecom, Alibaba, Amadeus, ATOS...

\subsection{HBase}

HBase est une base de données distribuée non-relationnelle. Cette technologie permet de stocker de larges quantités de données, et est très efficace pour les applications ayant un haut débit de données.

Hbase gère la réplication au sein du cluster, le sharding et le équilibrage de charge. Le requêtage est extrêmement rapide et des filtres peuvent être appliqués.

\textbf{Utilisé par :} Adobe, Airbnb, Facebook Messenger, Netflix...

\textbf{HBase} assure une cohérence stricte des écritures et lectures, c'est à dire qu'une lecture renvoie toujours le résultat de la dernière écriture effectuée.
HBase gère de manière automatique la réplication au sein du cluster ainsi que le basculement en cas de panne.

\subsection{Zeppelin}

\textbf{Zeppelin} fournit une interface web de visualisation de données. Son principal intérêt est d'être capable d'analyser et mettre en forme de grandes quantités de données, et de s'intégrer très bien aux autres technologies (faisant partie de l'écosystème Apache).

Cet outil fournit de nombreux graphes pour la visualisation de données, permettant de rapidement et facilement travailler sur de gros volumes.

Zeppelin, en tant que simple outil de visualisation, ne garantit en rien la tolérance aux fautes. Cependant, Zeppelin intervient en bout de chaîne et son interruption n'a aucune incidence sur le fonctionnement du reste des composants du système. 


\section{Architecture}

\subsection{Producer : Flink}

Le \textbf{Producer} s'inscrit sur un flux twitter pour récupérer les tweets sur les régions désirées. A chaque réception de tweets, le produceur distribue les tweets sur \textbf{Kafka}

\subsection{Distributeur : Kafka}

Notre \textbf{Kafka} est découpé en ville, chaque \textit{topic} correspond à une ville. Kafka stocke message par message les tweets pour chaque \textit{topic}. 

\subsection{Traitement : Flink}

Nos \textbf{Flink} de traitement sont découpés en ville. Il récupère message par message, les tweets de leur ville dans le \textit{topic} associé dans \textbf{Kafka}. Il traite chaque tweet afin d'attribuer une appréciation au tweet. 

\subsection{Base de données : HBase}

Nous stockons chaque tweet dans une table correspondant à sa ville. 


\subsection{Visualisation : Zeppelin}

Nous visualisons nos données grâce à \textbf{Zeppelin}

\section{Comportement}

Nous considérons 3 serveurs. Nous souhaitons garantir le fonctionnement du service en tolérant deux fautes. 

- Lorsque 3 machines sont en vie, alors le service fonctionne correctement.
- Lorsque 2 machines sont en vie, alors le service fonctionne correctement et cherche à remettre en place la machine en faute.
- Lorsque 1 machine est en vie, alors le service fonctionne correctement et à remettre en place les machines en faute. 

Nous éxécutons le projet sur 3 villes : Paris, London, NYC

\subsection{Configuration}

\subsubsection{Kafka}

\begin{itemize}
\item Installé sur toutes les machines. 
\item Un détecteur de faute se chargera de détecter les machines fautives.
\item Un correcteur de faute cherchera à redémarrer la ou les machines fautives.
\end{itemize}

\subsubsection{Flink}

\begin{itemize}
\item Installé sur 3 machines. 
\item Un détecteur de faute se chargera de répartir les différentes configurations de Flink sur les différents serveurs en vie
\end{itemize}

\subsubsection{Hbase}

\begin{itemize}
\item Installé sur 3 machines. 
\end{itemize}	

\subsubsection{Zeppelin}

\begin{itemize}
\item Installé sur 3 machines. 
\item Un détecteur de faute cherchera à redémarrer la ou les machines fautives 
\end{itemize}

\section{Configurations et Aides}

\subsubsection{Configuration \& Aide pour Flink Producer}

%## [Pour commencer](Help/FLINK.md)


\subsubsection{Information}

Les sources des tâches sont dans le dossier `source/apps/FlinkProducer`. 

\begin{itemize}
\item FakeTwitter : Envoi periodiquement un tweet à kafka, dans une table définie aléatoirement. 
\end{itemize} 


\subsubsection{Objectifs}

Récupérer tous les tweets des lieux où nous souhaitons effectuer nos calculs. Sépare les tweets par lieu et les envoi sur Kafka sur le bon topic. 


\subsubsection{Paramètres}

\begin{itemize}
\item \verb!number of tweet par second! 
\item \verb!bootstrap server!
\end{itemize}

\begin{verbatim}
# Run example
bin/flink run FakeTwitter.jar 10 worker1:9092,worker2:9092,worker3:9092
\end{verbatim}

\subsubsection{Autres}

Lorsque des données sont perdues, nous ne cherchons pas à les récupérer. Si les calculs échouent de même. N'oublions pas l'esprit du Streaming. 
Si Kafka n'est pas accessible à un moment, on ne cherche pas a envoyer de nouveau les tweets, on les oublie. 



\subsection{Configuration d'Apache Kafka}

%## [Pour commencer](Help/KAFKA.md)

\subsubsection{Gestion manuelle du cycle de vie}

Si l'on souhaite gérer manuellement le cycle de vie d'Apache Kafka 
(c'est-à-dire sans avoir recours à \textit{ServiceWatcher}), il est 
recommandé d'utiliser \textit{systemd} :

\begin{verbatim}
# Monitorer l'état d'Apache Kafka.
sudo systemctl status kafka
# Démarrer le service associé à Apache Kafka.
sudo systemctl start kafka
# Stopper le service associé à Apache Kafka.
sudo systemctl stop kafka
\end{verbatim}

De plus, \textit{systemd} essayera de redémarrer Apache Kafka en cas d'erreur
inopinée.

\subsection{Configuration \& Aide pour Flink Processing}

%## [Pour commencer](Help/FLINK.md)


\subsubsection{Information}

Les sources des tâches sont dans le dossier \verb!source/apps/FlinkProcess!. 

\begin{itemize}
\item KafkaToConsole : Récupère les tweets de Kafka et les écrits dans la console
\item KafkaToHBase : Récupère les tweets de Kafka et les envoi à HBase
\end{itemize}

\subsubsection{Objectifs}

A chaque tweet, nous estimons son humeur et ecrivons le resultat dans la base de données. 

Les tweets sont continuellement récupérés de Kafka, estimés et enregistrés dans HBase. 

\subsubsection{Paramètres}

\begin{itemize}
\item \verb!--port <flink port>! 
\item \verb!--topic <place>!
\item \verb!--bootstrap.servers <bootstrap servers>!
\item \verb!--zookeeper.connect <zookeeper machine:port>!
\item \verb!--group.id <consumer group>!
\item \verb!--hbasetable <topic name>!
\item \verb!--hbasequorum <hbase quorum>!
\item \verb!--hbaseport <port of hbase quorum>!
\end{itemize}

\begin{verbatim}
# Run example
bin/flink run KafkaConsoleBridge.jar \
	--port 9000 \
	--topic paris \
	--bootstrap.servers worker1:9092,worker2:9092,worker3:9092 \
	--zookeeper.connect localhost:2181 \
	--group.id parisconsumer \
	--hbasetable paris_tweets \
	--hbasequorum worker1,worker2,worker3 \
	--hbaseport 2181
\end{verbatim}

\subsubsection{Autres}

Lorsque des données sont perdues, nous ne cherchons pas à les récupérer. Si les calculs échouent de même. N'oublions pas l'esprit du Streaming. 

\subsection{Configuration \& Aide pour HBase}

%## [Pour commencer](Help/HBASE.md)

\subsubsection{Information}

Pour découper l'enregistrement des tweets, on enregistre chaque tweet dans le lieu correspondant. C'est à dire, chaque lieu à sa propre table. De cette manière, on evite l'utilisation des filters. Le nom de la table est \textbf{<Place>\_Tweets}

\subsubsection{Structure des tables}

Table \textbf{<Place>\_Tweet}
- \textbf{\textit{RowIdentifier}} - \textit{timestamp\_UniqID} : identifiant unique.
- \textbf{user} : propriétés de l'utilisateur auteur du tweet
- \textbf{tweet} : propriétés du tweet
- \textbf{feeling} : estimation de l'humeur du tweet


%\subsection{[Zeppelin](./misc/ZEPPELIN.md)

\section{Informations}

Environnement de déploiement : \textbf{Vagrant}

Outil de deploiement : \textbf{Rake}

\section{Pour commencer}

\subsection{Lancer en developpement local}

\begin{verbatim}
export RAKE_ENV=development
rake vagrant:up
./deploy.sh
\end{verbatim}

\subsection{Lancer en production}

Le document hosts.yml contient les informations de connexion aux machines de production. 

\begin{verbatim}
export RAKE_ENV=production
./deploy.sh
\end{verbatim}


\section{Utilisation de Rake pour les tâches de maintenance}

\subsection{Installation}

\begin{verbatim}
\section{Installation de Bundler (once)
gem install bundler

\section{Installation des dépendances
\section{En cas d'incompatibilité avec Gemfile.lock sur le dépôt : bundle update
bundle
\end{verbatim}

\subsection{Environnement}

\begin{verbatim}
\section{Utilisation de l'environnement de développement
export RAKE_ENV=development
\section{Ne pas oublier de démarrer les machines virtuelles pour l'environnement de développement
rake vagrant:up

\section{Utilisation de l'environnement de production
export RAKE_ENV=production
\end{verbatim}

\subsection{Affichage de l'aide}

\begin{verbatim}
\section{Listing des tâches Rake avec leur description
rake -T
\end{verbatim}

\subsection{Deploiement}

\begin{verbatim}
\section{Déploiement et provisioning
rake deploy

\section{Uniquement sur deux serveurs (définis dans hosts.yml)
rake deploy[server-2;server-3]

\section{Connexion SSH
rake ssh server-1
\end{verbatim}

\subsection{Services}

En l'absence de services spécifiés pour ces commandes, l'ensemble de services
concerné est celui défini dans la section \textit{services} du fichier de configuration
courant. Ces commandes (à l'exception de `services:watcher`) correspondent
à l'appel de `systemctl` sur les machines cibles.

\begin{verbatim}
# Démarrage des services
rake services:start

# Statut des services
rake services:status

# Arrêt des services
rake services:stop

# Kill des services
rake services:kill

# Kill tous les services de <server1> et <server2>
rake services:kill[<server1>;<server2>]

# Kill les services <service1> et <service2> de <server1> et <server2>
rake services:kill[<server1>;<server2>,<service1>;<service2>]

# Kill les services <service1> et <service2> sur tous les serveurs
rake services:kill[,<service1>;<service2>]

# Activation au démarrage (enable)
rake services:enable
\end{verbatim}

\subsection{Execution OneShot de commande}

\begin{verbatim}
# Lancer la commande <commande> (défini dans le yaml config)
rake run:<commande>[<server1>,<server2>]
\end{verbatim}


\subsection{Tests automatisés}

Le fonctionnement de l'infrastructure actuelle (selon \verb!$RAKE_ENV!) peut être
validé par l'exécution de tests automatisés, tels que définis dans le dossier
\verb!features/!.

\begin{verbatim}
# Exécution de tous les tests
rake features

# Exécution des tests de déploiement
rake features:deployment

# Exécution des tests du composant service_watcher
rake features:service_watcher

# Exécution des tests de contrôle des services systemd
rake features:services
\end{verbatim}


\section{Environnement de test Vagrant}

Le dossier vagrant contient :
\begin{itemize}
	\item  \verb!Vagrantfile! : définition de machines virtuelles de test
	\item  \verb!vagrant-hosts.yml! : configuration des différentes machines de test
\end{itemize}

Pour utiliser cet environnement de test :

\begin{itemize}
\item Installer [Vagrant](https://www.vagrantup.com/).
\item Installer [VirtualBox](https://www.virtualbox.org/).
\item Installer le plugin "vagrant-hostmanager" :
\end{itemize}

\begin{verbatim}
vagrant plugin install vagrant-hostmanager
\end{verbatim}

\begin{itemize}
\item Suivre les instructions de \texttt{https://github.com/devopsgroup-io/vagrant-hostmanager\#passwordless-sudo} pour éviter la demande de mot de passe sudo à chaque démarrage des machines virtuelles.
\end{itemize}
Une fois que tout est installé, les commandes suivantes peuvent être utilisées :

\begin{verbatim}
# Démarrage des machines définies dans le Vagrantfile
# La première fois, les images vont être téléchargées et configurées. Cela prend du temps.
# Les fois suivantes les machines installées seront reprises dans leur état actuel.
vagrant up

# Connexion SSH à une des machines
vagrant ssh worker1

# Recréer les machines suite à une modification du Vagrantfile
vagrant reload

# Mise en pause des machines
vagrant suspend

# Arrêt des machines (shutdown)
vagrant halt

# Destruction des machines (pour réinstallation propre)
vagrant destroy
\end{verbatim}

Si \_vagrant-hostmanager\_ est configuré correctement, les machines peuvent être contactées en utilisant les noms \verb!worker1!, \verb!worker2! etc. plutôt que leurs adresses IP.

Le réseau privé utilisé pour les machines Vagrant est 10.20.1.0/24. Par défaut l'adresse de la machine hôte est 10.20.1.1.

\subsection{Troubleshooting}

\verb!#vagrant plugin install vagrant-hostmanager échoue!

sous debian il peut être nécessaire d'installer le paquet ruby-dev.






\end{document}
